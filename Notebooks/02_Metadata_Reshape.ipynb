{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12dc0fd",
   "metadata": {},
   "source": [
    "This notebook focuses on reshaping metadata files (the Excel dictionaries that describe survey variables). It extracts the Sheet 1 and Sheet 2 Metadata (for context, there are a total of two metadata sheets available for all survey months for decoding purposes) across all years/months and saves them into a new folder (NEW Metadata Sheet 1 CSV's and NEW Metadata Sheet 2 CSV's).\n",
    "\n",
    "- it loads metadata files from the inventory.\n",
    "\n",
    "- It extracts extended variable names and descriptions from Sheet 1 (columns E and F).\n",
    "\n",
    "- It cleans empty rows and trims whitespace.\n",
    "\n",
    "- It saves reshaped metadata into a dedicated folder (data/interim/metadata_sheet1/).\n",
    "\n",
    "- Batch process: Load raw metadata, reshape variables, save clean CSVs.\n",
    "\n",
    "- Verification: Compare raw vs reshaped counts to ensure no variables or descriptions were lost.\n",
    "\n",
    "**INTENT:**  Metadata often contains empty spaces and inconsistent formatting, which show up as NaN in analysis. By reshaping metadata first, we ensure that variable names and descriptions are clean and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092df733",
   "metadata": {},
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ea085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings loaded.\n",
      "Inventory loaded. Years available: ['2018', '2019', '2022', '2023', '2024']\n",
      "Reshaped metadata will be temporarily saved to: data\\interim\\NEW_metadata_sheet1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Load settings\n",
    "with open(Path(\"./data/interim/config.json\")) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "BASE_PATH = Path(cfg[\"BASE_PATH\"])\n",
    "INTERIM_DIR = Path(cfg[\"INTERIM_DIR\"])\n",
    "\n",
    "print(\"Settings loaded.\")\n",
    "\n",
    "# Load inventory (already built in 01_Inventory.ipynb)\n",
    "with open(INTERIM_DIR / \"inventory.json\") as f:\n",
    "    inventory = json.load(f)\n",
    "\n",
    "print(\"Inventory loaded. Years available:\", list(inventory.keys()))\n",
    "\n",
    "# Create NEW local subfolder for reshaped metadata outputs\n",
    "metadata_out = INTERIM_DIR / \"NEW_metadata_sheet1\"\n",
    "metadata_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Reshaped metadata will be temporarily saved to:\", metadata_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68d110",
   "metadata": {},
   "source": [
    "#### Load dataset (optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2978a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(year, month, filetype=\"survey\", sheet_number=None):\n",
    "    \"\"\"\n",
    "    Load a dataset from the inventory.\n",
    "    - year: str, e.g., \"2018\"\n",
    "    - month: str, e.g., \"January\"\n",
    "    - filetype: \"survey\" or \"metadata\"\n",
    "    - sheet_number: 0 (Sheet 1) or 1 (Sheet 2) for metadata\n",
    "    \"\"\"\n",
    "    file_info = next((f for f in inventory[year][month] if f[\"filetype\"] == filetype), None)\n",
    "    if not file_info:\n",
    "        raise ValueError(f\"No {filetype} file found for {month} {year}\")\n",
    "\n",
    "    file_path = BASE_PATH / year / file_info[\"filename\"]\n",
    "\n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "    if sheet_number is not None:\n",
    "        return pd.read_excel(file_path, sheet_name=sheet_number, engine=\"openpyxl\")\n",
    "    return pd.read_excel(file_path, engine=\"openpyxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01778fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== January 2018 Metadata Sheet 1 (Raw) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUEST</th>\n",
       "      <th>Questionnaire</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_IDS0</td>\n",
       "      <td>(Id Items)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFREG</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFPRV</td>\n",
       "      <td>Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFPRRCD</td>\n",
       "      <td>Province Recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QUEST  Questionnaire Unnamed: 2  Unnamed: 3 Unnamed: 4  \\\n",
       "0    NaN            NaN      _IDS0  (Id Items)        NaN   \n",
       "1    NaN            NaN        NaN         NaN     PUFREG   \n",
       "2    NaN            NaN        NaN         NaN     PUFPRV   \n",
       "3    NaN            NaN        NaN         NaN   PUFPRRCD   \n",
       "4    NaN            NaN        NaN         NaN   PUFHHNUM   \n",
       "\n",
       "                           Unnamed: 5  \n",
       "0                                 NaN  \n",
       "1                              Region  \n",
       "2                            Province  \n",
       "3                     Province Recode  \n",
       "4  Household Unique Sequential Number  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the first sheet of January 2018 metadata\n",
    "january_2018_metadata_sheet1 = load_dataset(\"2018\", \"January\", \"metadata\", sheet_number=0)\n",
    "\n",
    "# View the first few rows\n",
    "print(\"=== January 2018 Metadata Sheet 1 (Raw) ===\")\n",
    "display(january_2018_metadata_sheet1.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345cc9d",
   "metadata": {},
   "source": [
    "### Sheet 1 Metadata Reshape Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701184c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "662146c5",
   "metadata": {},
   "source": [
    "#### Extract variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0588714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables(df):\n",
    "    \"\"\"\n",
    "    Extract variable names and descriptions from metadata Sheet 1.\n",
    "    Columns E and F (index 4 and 5) contain variable codes and descriptions.\n",
    "    Returns a clean DataFrame with ['Variable', 'Description'].\n",
    "    \"\"\"\n",
    "    df_vars = df.iloc[:, 4:6].copy()\n",
    "    df_vars.columns = ['Variable', 'Description']\n",
    "\n",
    "    # Drop empty rows\n",
    "    df_vars = df_vars[df_vars['Variable'].notna() & (df_vars['Variable'].astype(str).str.strip() != '')]\n",
    "\n",
    "    # Clean whitespace\n",
    "    df_vars['Variable'] = df_vars['Variable'].astype(str).str.strip()\n",
    "    df_vars['Description'] = df_vars['Description'].astype(str).str.strip()\n",
    "\n",
    "    return df_vars.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1706c90",
   "metadata": {},
   "source": [
    "#### Batch process (year by year option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573d7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_sheet1_metadata(inventory, base_output_path, years=None):\n",
    "    \"\"\"\n",
    "    Process metadata Sheet 1 for selected years.\n",
    "    Saves reshaped CSVs into NEW_metadata_sheet1 folder.\n",
    "    \"\"\"\n",
    "    success_count, failure_count, skipped_count = 0, 0, 0\n",
    "    errors_log = []\n",
    "\n",
    "    main_folder_path = os.path.join(base_output_path, \"data\", \"interim\", \"NEW_metadata_sheet1\")\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "\n",
    "    print(\"--- STARTING BATCH PROCESS ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Limit to selected years if provided\n",
    "    years_to_process = years if years else inventory.keys()\n",
    "\n",
    "    for year in years_to_process:\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "\n",
    "        for month, files_list in inventory[year].items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            if not has_metadata:\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", 0)\n",
    "                clean_df = extract_variables(raw_df)\n",
    "\n",
    "                filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "                full_save_path = os.path.join(year_folder_path, filename)\n",
    "                clean_df.to_csv(full_save_path, index=False)\n",
    "\n",
    "                print(f\"[OK] Saved: {year}/{filename}\")\n",
    "                success_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed {month} {year}: {e}\")\n",
    "                errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                failure_count += 1\n",
    "\n",
    "    print(\"\\n=== PROCESSING SUMMARY REPORT ===\")\n",
    "    print(f\"Total Successfully Saved: {success_count}\")\n",
    "    print(f\"Total Failed:             {failure_count}\")\n",
    "    print(f\"Total Skipped (No File):  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        if errors_log:\n",
    "            print(\"Error Details:\")\n",
    "            for err in errors_log:\n",
    "                print(f\" - {err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa00671",
   "metadata": {},
   "source": [
    "#### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b637f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_output_path, years=None):\n",
    "    \"\"\"\n",
    "    Compare raw vs reshaped metadata counts for assurance.\n",
    "    Returns a DataFrame with PASS/FAIL per year/month.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    reshaped_folder = os.path.join(base_output_path, \"data\", \"interim\", \"NEW_metadata_sheet1\")\n",
    "\n",
    "    years_to_process = years if years else inventory.keys()\n",
    "\n",
    "    for year in years_to_process:\n",
    "        for month, files_list in inventory[year].items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=0)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 1 ({e})\")\n",
    "                continue\n",
    "\n",
    "            reshaped_file_path = os.path.join(reshaped_folder, year, f\"Sheet1_{month}_{year}.csv\")\n",
    "            if not os.path.exists(reshaped_file_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped CSV missing!\")\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_file_path)\n",
    "\n",
    "            raw_vars = raw_df.iloc[:,4].dropna().astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']\n",
    "            raw_descs = raw_df.iloc[:,5].dropna().astype(str).str.strip()\n",
    "            raw_descs = raw_descs[raw_descs != '']\n",
    "\n",
    "            reshaped_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            reshaped_vars = reshaped_vars[reshaped_vars != '']\n",
    "            reshaped_descs = reshaped_df['Description'].astype(str).str.strip()\n",
    "            reshaped_descs = reshaped_descs[reshaped_descs != '']\n",
    "\n",
    "            status = \"PASS\" if (len(raw_vars) == len(reshaped_vars) and len(raw_descs) == len(reshaped_descs)) else \"FAIL\"\n",
    "            if status == \"FAIL\":\n",
    "                print(f\"[MISMATCH] {month} {year} - Variables: {len(raw_vars)} vs {len(reshaped_vars)}, \"\n",
    "                      f\"Descriptions: {len(raw_descs)} vs {len(reshaped_descs)}\")\n",
    "\n",
    "            results.append({\n",
    "                'Year': year, 'Month': month,\n",
    "                'Raw Variable Count': len(raw_vars),\n",
    "                'Reshaped Variable Count': len(reshaped_vars),\n",
    "                'Raw Description Count': len(raw_descs),\n",
    "                'Reshaped Description Count': len(reshaped_descs),\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d47b42",
   "metadata": {},
   "source": [
    "#### Run batch and verify  (2018 trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea0bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING BATCH PROCESS ---\n",
      "Target Directory: .\\data\\interim\\NEW_metadata_sheet1\n",
      "--------------------------------------------------\n",
      "[OK] Saved: 2018/Sheet1_April_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_July_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_January_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_October_2018.csv\n",
      "\n",
      "=== PROCESSING SUMMARY REPORT ===\n",
      "Total Successfully Saved: 4\n",
      "Total Failed:             0\n",
      "Total Skipped (No File):  0\n",
      "----------------------------------------\n",
      "STATUS: COMPLETE SUCCESS\n",
      "=== Verification Results (Local) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Variable Count</th>\n",
       "      <th>Reshaped Variable Count</th>\n",
       "      <th>Raw Description Count</th>\n",
       "      <th>Reshaped Description Count</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Month  Raw Variable Count  Reshaped Variable Count  \\\n",
       "0  2018    April                  50                       50   \n",
       "1  2018  January                  50                       50   \n",
       "2  2018     July                  51                       51   \n",
       "3  2018  October                  51                       51   \n",
       "\n",
       "   Raw Description Count  Reshaped Description Count Status  \n",
       "0                     50                          50   PASS  \n",
       "1                     50                          50   PASS  \n",
       "2                     51                          51   PASS  \n",
       "3                     51                          51   PASS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trial run: process only 2018 locally (fast, avoids Drive write)\n",
    "batch_process_sheet1_metadata(inventory, \".\", years=[\"2018\"])\n",
    "\n",
    "# Verify outputs for 2018\n",
    "verification_df = batch_verify_sheet1_variable_and_description_count_verbose(inventory, \".\", years=[\"2018\"])\n",
    "\n",
    "print(\"=== Verification Results (Local) ===\")\n",
    "display(verification_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d575b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== January 2018 Metadata Sheet 1 (Reshaped) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUFREG</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUFPRV</td>\n",
       "      <td>Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUFPRRCD</td>\n",
       "      <td>Province Recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUFURB2K10</td>\n",
       "      <td>2010Urban-RuralFIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PUFPWGTPRV</td>\n",
       "      <td>Final Weight Based on Projection (provincial p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PUFSVYMO</td>\n",
       "      <td>Survey Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PUFSVYYR</td>\n",
       "      <td>Survey Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PUFPSU</td>\n",
       "      <td>Psu Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PUFRPL</td>\n",
       "      <td>Replicate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable                                        Description\n",
       "0      PUFREG                                             Region\n",
       "1      PUFPRV                                           Province\n",
       "2    PUFPRRCD                                    Province Recode\n",
       "3    PUFHHNUM                 Household Unique Sequential Number\n",
       "4  PUFURB2K10                                2010Urban-RuralFIES\n",
       "5  PUFPWGTPRV  Final Weight Based on Projection (provincial p...\n",
       "6    PUFSVYMO                                       Survey Month\n",
       "7    PUFSVYYR                                        Survey Year\n",
       "8      PUFPSU                                         Psu Number\n",
       "9      PUFRPL                                          Replicate"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the reshaped January 2018 metadata (Sheet 1) from the saved CSV\n",
    "reshaped_jan_2018 = pd.read_csv(INTERIM_DIR / \"NEW_metadata_sheet1\" / \"2018\" / \"Sheet1_January_2018.csv\")\n",
    "\n",
    "print(\"=== January 2018 Metadata Sheet 1 (Reshaped) ===\")\n",
    "display(reshaped_jan_2018.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f29b8",
   "metadata": {},
   "source": [
    "#### Batch Automation (Redirect to Drive/Base_path as new folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae3e5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_sheet1_metadata_to_drive(inventory, base_output_path, years=None):\n",
    "    \"\"\"\n",
    "    Process metadata Sheet 1 for selected years.\n",
    "    Saves reshaped CSVs directly into NEW Metadata Sheet 1 CSV's in Google Drive.\n",
    "    Prints a progress report while running.\n",
    "    \"\"\"\n",
    "    success_count, failure_count, skipped_count = 0, 0, 0\n",
    "    errors_log = []\n",
    "\n",
    "    main_folder_name = \"NEW Metadata Sheet 1 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "\n",
    "    # Count total tasks for progress tracking\n",
    "    total_tasks = sum(\n",
    "        1 for year in (years if years else inventory.keys())\n",
    "        for month, files_list in inventory[year].items()\n",
    "        if any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "    )\n",
    "    current_task = 0\n",
    "\n",
    "    print(\"--- STARTING BATCH PROCESS TO DRIVE ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    years_to_process = years if years else inventory.keys()\n",
    "\n",
    "    for year in years_to_process:\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "\n",
    "        for month, files_list in inventory[year].items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            if not has_metadata:\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "\n",
    "            current_task += 1\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", 0)\n",
    "                clean_df = extract_variables(raw_df)\n",
    "\n",
    "                filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "                full_save_path = os.path.join(year_folder_path, filename)\n",
    "                clean_df.to_csv(full_save_path, index=False)\n",
    "\n",
    "                print(f\"[{current_task}/{total_tasks}] [OK] Saved: {year}/{filename}\")\n",
    "                success_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[{current_task}/{total_tasks}] [ERROR] Failed {month} {year}: {e}\")\n",
    "                errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                failure_count += 1\n",
    "\n",
    "    print(\"\\n=== PROCESSING SUMMARY REPORT ===\")\n",
    "    print(f\"Total Successfully Saved: {success_count}\")\n",
    "    print(f\"Total Failed:             {failure_count}\")\n",
    "    print(f\"Total Skipped (No File):  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "        print(f\"All files are now located in: {main_folder_path}\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        if errors_log:\n",
    "            print(\"Error Details:\")\n",
    "            for err in errors_log:\n",
    "                print(f\" - {err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e3b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING BATCH PROCESS TO DRIVE ---\n",
      "Target Directory: G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW Metadata Sheet 1 CSV's\n",
      "--------------------------------------------------\n",
      "[1/40] [OK] Saved: 2018/Sheet1_April_2018.csv\n",
      "[2/40] [OK] Saved: 2018/Sheet1_July_2018.csv\n",
      "[3/40] [OK] Saved: 2018/Sheet1_January_2018.csv\n",
      "[4/40] [OK] Saved: 2018/Sheet1_October_2018.csv\n",
      "[5/40] [OK] Saved: 2019/Sheet1_April_2019.csv\n",
      "[6/40] [OK] Saved: 2019/Sheet1_July_2019.csv\n",
      "[7/40] [OK] Saved: 2019/Sheet1_October_2019.csv\n",
      "[8/40] [OK] Saved: 2019/Sheet1_January_2019.csv\n",
      "[9/40] [OK] Saved: 2022/Sheet1_July_2022.csv\n",
      "[10/40] [OK] Saved: 2022/Sheet1_June_2022.csv\n",
      "[11/40] [OK] Saved: 2022/Sheet1_April_2022.csv\n",
      "[12/40] [OK] Saved: 2022/Sheet1_August_2022.csv\n",
      "[13/40] [OK] Saved: 2022/Sheet1_December_2022.csv\n",
      "[14/40] [OK] Saved: 2022/Sheet1_February_2022.csv\n",
      "[15/40] [OK] Saved: 2022/Sheet1_January_2022.csv\n",
      "[16/40] [OK] Saved: 2022/Sheet1_March_2022.csv\n",
      "[17/40] [OK] Saved: 2022/Sheet1_May_2022.csv\n",
      "[18/40] [OK] Saved: 2022/Sheet1_November_2022.csv\n",
      "[19/40] [OK] Saved: 2022/Sheet1_October_2022.csv\n",
      "[20/40] [OK] Saved: 2022/Sheet1_September_2022.csv\n",
      "[21/40] [OK] Saved: 2023/Sheet1_April_2023.csv\n",
      "[22/40] [OK] Saved: 2023/Sheet1_August_2023.csv\n",
      "[23/40] [OK] Saved: 2023/Sheet1_December_2023.csv\n",
      "[24/40] [OK] Saved: 2023/Sheet1_February_2023.csv\n",
      "[25/40] [OK] Saved: 2023/Sheet1_January_2023.csv\n",
      "[26/40] [OK] Saved: 2023/Sheet1_July_2023.csv\n",
      "[27/40] [OK] Saved: 2023/Sheet1_June_2023.csv\n",
      "[28/40] [OK] Saved: 2023/Sheet1_March_2023.csv\n",
      "[29/40] [OK] Saved: 2023/Sheet1_November_2023.csv\n",
      "[30/40] [OK] Saved: 2023/Sheet1_October_2023.csv\n",
      "[31/40] [OK] Saved: 2023/Sheet1_September_2023.csv\n",
      "[32/40] [OK] Saved: 2023/Sheet1_May_2023.csv\n",
      "[33/40] [OK] Saved: 2024/Sheet1_February_2024.csv\n",
      "[34/40] [OK] Saved: 2024/Sheet1_April_2024.csv\n",
      "[35/40] [OK] Saved: 2024/Sheet1_January_2024.csv\n",
      "[36/40] [OK] Saved: 2024/Sheet1_August_2024.csv\n",
      "[37/40] [OK] Saved: 2024/Sheet1_July_2024.csv\n",
      "[38/40] [OK] Saved: 2024/Sheet1_March_2024.csv\n",
      "[39/40] [OK] Saved: 2024/Sheet1_May_2024.csv\n",
      "[40/40] [OK] Saved: 2024/Sheet1_June_2024.csv\n",
      "\n",
      "=== PROCESSING SUMMARY REPORT ===\n",
      "Total Successfully Saved: 40\n",
      "Total Failed:             0\n",
      "Total Skipped (No File):  0\n",
      "----------------------------------------\n",
      "STATUS: COMPLETE SUCCESS\n",
      "All files are now located in: G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW Metadata Sheet 1 CSV's\n"
     ]
    }
   ],
   "source": [
    "# Run batch process for ALL years, saving directly to Drive\n",
    "batch_process_sheet1_metadata_to_drive(inventory, str(BASE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3d374",
   "metadata": {},
   "source": [
    "### Sheet 2 Metadata Reshape Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9cba356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_process_sheet2_metadata(inventory, base_output_path, years=None):\n",
    "    \"\"\"\n",
    "    Loops through the inventory to process 'Sheet 2' (Value Codes).\n",
    "    Saves reshaped CSVs into NEW Metadata Sheet 2 CSV's.\n",
    "    \"\"\"\n",
    "\n",
    "    success_count, failure_count, skipped_count = 0, 0, 0\n",
    "    errors_log = []\n",
    "\n",
    "    # 1. Define Main Folder Name (NEW folder for Sheet 2 outputs)\n",
    "    main_folder_name = \"NEW Metadata Sheet 2 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "\n",
    "    # Count total tasks for progress tracking\n",
    "    total_tasks = sum(\n",
    "        1 for year in (years if years else inventory.keys())\n",
    "        for month, files_list in inventory[year].items()\n",
    "        if any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "    )\n",
    "    current_task = 0\n",
    "\n",
    "    print(\"--- STARTING BATCH PROCESS (SHEET 2) ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Iterate through Inventory\n",
    "    years_to_process = years if years else inventory.keys()\n",
    "\n",
    "    for year in years_to_process:\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "\n",
    "        for month, files_list in inventory[year].items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            if not has_metadata:\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "\n",
    "            current_task += 1\n",
    "            try:\n",
    "                # A. Load raw Sheet 2 (Value Codes)\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=1)\n",
    "\n",
    "                # B. Clean whitespace (optional, but intentional)\n",
    "                raw_df = raw_df.applymap(lambda x: str(x).strip() if pd.notna(x) else x)\n",
    "\n",
    "                # C. Generate Filename\n",
    "                filename = f\"Sheet2_{month}_{year}.csv\"\n",
    "                full_save_path = os.path.join(year_folder_path, filename)\n",
    "\n",
    "                # D. Save\n",
    "                raw_df.to_csv(full_save_path, index=False)\n",
    "\n",
    "                print(f\"[{current_task}/{total_tasks}] [OK] Saved: {year}/{filename}\")\n",
    "                success_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[{current_task}/{total_tasks}] [ERROR] Failed {month} {year}: {e}\")\n",
    "                errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                failure_count += 1\n",
    "\n",
    "    # 3. Final Report\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      SHEET 2 PROCESSING SUMMARY\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Saved:    {success_count}\")\n",
    "    print(f\"Total Failed:   {failure_count}\")\n",
    "    print(f\"Total Skipped:  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "        print(f\"Files are syncing to: {main_folder_path}\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        for err in errors_log:\n",
    "            print(f\" - {err}\")\n",
    "    print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab1689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
