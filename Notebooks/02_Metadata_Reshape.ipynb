{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12dc0fd",
   "metadata": {},
   "source": [
    "This notebook focuses on reshaping metadata files (the Excel dictionaries that describe survey variables). It extracts the Sheet 1 Metadata (for context, there are a total of two metadata sheets available for all survey months for decoding purposes) across all years/months and saves them into a new folder (NEW Metadata Sheet 1 CSV's).\n",
    "\n",
    "- it loads metadata files from the inventory.\n",
    "\n",
    "- It extracts extended variable names and descriptions from Sheet 1 (columns E and F).\n",
    "\n",
    "- It cleans empty rows and trims whitespace.\n",
    "\n",
    "- It saves reshaped metadata into a dedicated folder (data/interim/metadata_sheet1/).\n",
    "\n",
    "- Batch process: Load raw metadata, reshape variables, save clean CSVs.\n",
    "\n",
    "- Verification: Compare raw vs reshaped counts to ensure no variables or descriptions were lost.\n",
    "\n",
    "**INTENT:**  Metadata often contains empty spaces and inconsistent formatting, which show up as NaN in analysis. By reshaping metadata first, we ensure that variable names and descriptions are clean and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092df733",
   "metadata": {},
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Load settings\n",
    "with open(Path(\"./data/interim/config.json\")) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "BASE_PATH = Path(cfg[\"BASE_PATH\"])\n",
    "INTERIM_DIR = Path(cfg[\"INTERIM_DIR\"])\n",
    "\n",
    "print(\"Settings loaded.\")\n",
    "\n",
    "# Load inventory (already built in 01_Inventory.ipynb)\n",
    "with open(INTERIM_DIR / \"inventory.json\") as f:\n",
    "    inventory = json.load(f)\n",
    "\n",
    "print(\"Inventory loaded. Years available:\", list(inventory.keys()))\n",
    "\n",
    "# Create NEW local subfolder for reshaped metadata outputs\n",
    "metadata_out = INTERIM_DIR / \"NEW_metadata_sheet1\"\n",
    "metadata_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Reshaped metadata will be saved to:\", metadata_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68d110",
   "metadata": {},
   "source": [
    "#### Load dataset (optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(year, month, filetype=\"survey\", sheet_number=None):\n",
    "    \"\"\"\n",
    "    Load a dataset from the inventory.\n",
    "    - year: str, e.g., \"2018\"\n",
    "    - month: str, e.g., \"January\"\n",
    "    - filetype: \"survey\" or \"metadata\"\n",
    "    - sheet_number: 0 (Sheet 1) or 1 (Sheet 2) for metadata\n",
    "    \"\"\"\n",
    "    file_info = next((f for f in inventory[year][month] if f[\"filetype\"] == filetype), None)\n",
    "    if not file_info:\n",
    "        raise ValueError(f\"No {filetype} file found for {month} {year}\")\n",
    "\n",
    "    file_path = BASE_PATH / year / file_info[\"filename\"]\n",
    "\n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "    if sheet_number is not None:\n",
    "        # Optimization: only read columns E and F for metadata Sheet 1\n",
    "        return pd.read_excel(file_path, sheet_name=sheet_number, usecols=[4,5])\n",
    "    return pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662146c5",
   "metadata": {},
   "source": [
    "#### Extract variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables(df):\n",
    "    \"\"\"\n",
    "    Extract variable names and descriptions from metadata Sheet 1.\n",
    "    Columns E and F contain variable codes and descriptions.\n",
    "    Returns a clean DataFrame with ['Variable', 'Description'].\n",
    "    \"\"\"\n",
    "    df_vars = df.iloc[:, 4:6].copy()\n",
    "    df_vars.columns = ['Variable', 'Description']\n",
    "\n",
    "    # Drop empty rows\n",
    "    df_vars = df_vars[df_vars['Variable'].notna() & (df_vars['Variable'].astype(str).str.strip() != '')]\n",
    "\n",
    "    # Clean whitespace\n",
    "    df_vars['Variable'] = df_vars['Variable'].astype(str).str.strip()\n",
    "    df_vars['Description'] = df_vars['Description'].astype(str).str.strip()\n",
    "\n",
    "    return df_vars.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1706c90",
   "metadata": {},
   "source": [
    "#### Batch process (year by year option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_sheet1_metadata(inventory, base_output_path):\n",
    "    \"\"\"\n",
    "    Loops through inventory, loads Sheet 1 metadata,\n",
    "    reshapes it, and saves into NEW folder hierarchy.\n",
    "    \"\"\"\n",
    "    success_count, failure_count, skipped_count = 0, 0, 0\n",
    "    errors_log = []\n",
    "\n",
    "    main_folder_name = \"NEW Metadata Sheet 1 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "\n",
    "    print(\"--- STARTING BATCH PROCESS ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            if not has_metadata:\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", 0)\n",
    "                clean_df = extract_variables(raw_df)\n",
    "\n",
    "                filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "                full_save_path = os.path.join(year_folder_path, filename)\n",
    "                clean_df.to_csv(full_save_path, index=False)\n",
    "\n",
    "                print(f\"[OK] Saved: {year}/{filename}\")\n",
    "                success_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed {month} {year}: {e}\")\n",
    "                errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                failure_count += 1\n",
    "\n",
    "    print(\"\\n=== PROCESSING SUMMARY REPORT ===\")\n",
    "    print(f\"Total Successfully Saved: {success_count}\")\n",
    "    print(f\"Total Failed:             {failure_count}\")\n",
    "    print(f\"Total Skipped (No File):  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        if errors_log:\n",
    "            print(\"Error Details:\")\n",
    "            for err in errors_log:\n",
    "                print(f\" - {err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa00671",
   "metadata": {},
   "source": [
    "#### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Compares raw vs reshaped metadata counts for assurance.\n",
    "    Returns a DataFrame with PASS/FAIL per year/month.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    reshaped_folder = os.path.join(base_path, \"NEW Metadata Sheet 1 CSV's\")\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=0)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 1 ({e})\")\n",
    "                continue\n",
    "\n",
    "            reshaped_file_path = os.path.join(reshaped_folder, year, f\"Sheet1_{month}_{year}.csv\")\n",
    "            if not os.path.exists(reshaped_file_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped CSV missing!\")\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_file_path)\n",
    "\n",
    "            raw_vars = raw_df.iloc[:, 4].dropna().astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']\n",
    "            raw_descs = raw_df.iloc[:, 5].dropna().astype(str).str.strip()\n",
    "            raw_descs = raw_descs[raw_descs != '']\n",
    "\n",
    "            reshaped_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            reshaped_vars = reshaped_vars[reshaped_vars != '']\n",
    "            reshaped_descs = reshaped_df['Description'].astype(str).str.strip()\n",
    "            reshaped_descs = reshaped_descs[reshaped_descs != '']\n",
    "\n",
    "            status = \"PASS\" if (len(raw_vars) == len(reshaped_vars) and len(raw_descs) == len(reshaped_descs)) else \"FAIL\"\n",
    "            if status == \"FAIL\":\n",
    "                print(f\"[MISMATCH] {month} {year} - Variables: {len(raw_vars)} vs {len(reshaped_vars)}, \"\n",
    "                      f\"Descriptions: {len(raw_descs)} vs {len(reshaped_descs)}\")\n",
    "\n",
    "            results.append({\n",
    "                'Year': year, 'Month': month,\n",
    "                'Raw Variable Count': len(raw_vars),\n",
    "                'Reshaped Variable Count': len(reshaped_vars),\n",
    "                'Raw Description Count': len(raw_descs),\n",
    "                'Reshaped Description Count': len(reshaped_descs),\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d47b42",
   "metadata": {},
   "source": [
    "#### Run batch and verify  (2018 trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch process\n",
    "batch_process_sheet1_metadata(inventory, BASE_PATH)\n",
    "\n",
    "# Run verification\n",
    "verification_df = batch_verify_sheet1_variable_and_description_count_verbose(inventory, BASE_PATH)\n",
    "\n",
    "print(\"=== Verification Results ===\")\n",
    "display(verification_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
